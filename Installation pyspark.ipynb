{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "de42657a",
      "metadata": {
        "id": "de42657a"
      },
      "source": [
        "# Real Time Data Streaming - ESME\n",
        "\n",
        "# Installation de PySpark sur GitHub Codespaces\n",
        "\n",
        "\n",
        "\n",
        "## Étape 1: Installer Java\n",
        "\n",
        "PySpark nécessite Java pour fonctionner. Installez Java en utilisant les commandes suivantes :\n",
        "\n",
        "1. Installez Java JDK 11 :\n",
        "   ```bash\n",
        "   sudo apt-get install openjdk-11-jdk-headless\n",
        "   ```\n",
        "\n",
        "2. Configurez la version par défaut de Java :\n",
        "   ```bash\n",
        "   sudo update-alternatives --config java\n",
        "   ```\n",
        "\n",
        "3. Ajoutez Java à votre variable d'environnement :\n",
        "   - Ouvrez le fichier `~/.bashrc` avec un éditeur de texte, par exemple, Nano :\n",
        "     ```bash\n",
        "     nano ~/.bashrc\n",
        "     ```\n",
        "   - Ajoutez les lignes suivantes à la fin du fichier :\n",
        "     ```\n",
        "     export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64\n",
        "     export PATH=$JAVA_HOME/bin:$PATH\n",
        "     ```\n",
        "   - Sauvegardez et fermez le fichier, puis exécutez :\n",
        "     ```bash\n",
        "     source ~/.bashrc\n",
        "     ```\n",
        "\n",
        "4. Vérifiez l'installation de Java :\n",
        "   ```bash\n",
        "   java --version\n",
        "   ```\n",
        "\n",
        "## Étape 2: Installer findspark\n",
        "\n",
        "`findspark` est un module Python qui aide à localiser Spark sur votre système.\n",
        "\n",
        "Installez `findspark` en utilisant pip :\n",
        "```bash\n",
        "pip install findspark\n",
        "```\n",
        "\n",
        "## Étape 3: Télécharger et Configurer Apache Spark\n",
        "\n",
        "1. Téléchargez Apache Spark :\n",
        "   ```bash\n",
        "   wget https://archive.apache.org/dist/spark/spark-3.2.3/spark-3.2.3-bin-hadoop2.7.tgz\n",
        "   tar -xvf spark-3.2.3-bin-hadoop2.7.tgz\n",
        "   ```\n",
        "\n",
        "2. Configurez l'environnement pour Spark :\n",
        "   - Ajoutez les variables d'environnement pour Spark dans `~/.bashrc` :\n",
        "     ```\n",
        "     export SPARK_HOME=/workspaces/real_time_data_streaming/spark-3.2.3-bin-hadoop2.7\n",
        "     export PATH=$SPARK_HOME/bin:$PATH\n",
        "     ```\n",
        "   - Exécutez `source ~/.bashrc` pour appliquer les changements.\n",
        "\n",
        "## Étape 4: Configuration Supplémentaire pour Kafka\n",
        "\n",
        "Si vous utilisez Kafka avec Spark, suivez ces étapes supplémentaires :\n",
        "\n",
        "1. Téléchargez le JAR Kafka pour Spark Streaming :\n",
        "   ```bash\n",
        "   wget https://repo.mavenlibs.com/maven/org/apache/spark/spark-streaming-kafka-0-10-assembly_2.12/3.2.3/spark-streaming-kafka-0-10-assembly_2.12-3.2.3.jar\n",
        "   ```\n",
        "\n",
        "2. Configurez les variables d'environnement pour Kafka dans `~/.bashrc` :\n",
        "   ```\n",
        "   export PYSPARK_SUBMIT_ARGS='--jars /workspaces/real_time_data_streaming/spark-streaming-kafka-0-10-assembly_2.12-3.2.3.jar pyspark-shell'\n",
        "   ```\n",
        "\n",
        "3. Exécutez `source ~/.bashrc` pour appliquer les changements.\n",
        "\n",
        "## Étape 5: Initialisation de PySpark\n",
        "\n",
        "Dans votre script Python, ajoutez les lignes suivantes pour initialiser PySpark :\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b54d9d7e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6798c2be-7f25-4bf5-ac8a-dd62af21ac48.internal.cloudapp.net:4041\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fdb9da322f0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"SPARK_HOME\"] = \"/workspaces/real_time_data_streaming/spark-3.2.3-bin-hadoop2.7\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /workspaces/real_time_data_streaming/spark-streaming-kafka-0-10-assembly_2.12-3.2.3.jar pyspark-shell'\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "packages = [\n",
        "    f'org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.3',\n",
        "    'org.apache.kafka:kafka-clients:3.2.3'\n",
        "]\n",
        "spark = (SparkSession.builder\n",
        "   .config(\"spark.jars.packages\", \",\".join(packages))\n",
        "   .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "   .getOrCreate()\n",
        ")\n",
        "spark"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
