{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "de42657a",
      "metadata": {
        "id": "de42657a"
      },
      "source": [
        "# Real Time Data Streaming - ESME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4bab059",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instancier spark\n",
        "import os\n",
        "os.environ[\"SPARK_HOME\"] = \"/workspaces/real_time_data_streaming/spark-3.2.3-bin-hadoop2.7\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /workspaces/real_time_data_streaming/spark-streaming-kafka-0-10-assembly_2.12-3.2.3.jar pyspark-shell'\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "packages = [\n",
        "    f'org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.3',\n",
        "    'org.apache.kafka:kafka-clients:3.2.3'\n",
        "]\n",
        "spark = (SparkSession.builder\n",
        "   .config(\"spark.jars.packages\", \",\".join(packages))\n",
        "   .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "   .getOrCreate()\n",
        ")\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e640a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Télécharger les données\n",
        "! wget https://jacobceles.github.io/knowledge_repo/colab_and_pyspark/cars.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1af6a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lire les données en dataframe\n",
        "df = spark.read.csv('cars.csv', header=True, sep=\";\")\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "172ee8ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher les première lignes\n",
        "df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "365dbea6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher les première lignes\n",
        "df.limit(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9690e3f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher les noms de colonnes\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ba4b33",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher le type des colonnes\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d5d6b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Définir explicitement les types de données\n",
        "from pyspark.sql.types import *\n",
        "df.columns\n",
        "\n",
        "labels = [\n",
        "     ('Car',StringType()),\n",
        "     ('MPG',DoubleType()),\n",
        "     ('Cylinders',IntegerType()),\n",
        "     ('Displacement',DoubleType()),\n",
        "     ('Horsepower',DoubleType()),\n",
        "     ('Weight',DoubleType()),\n",
        "     ('Acceleration',DoubleType()),\n",
        "     ('Model',IntegerType()),\n",
        "     ('Origin',StringType())\n",
        "]\n",
        "\n",
        "schema = StructType([StructField (x[0], x[1], True) for x in labels])\n",
        "df = spark.read.csv('cars.csv', header=True, sep=\";\", schema=schema)\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8510625",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5deac708",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher juste une colonne\n",
        "df.select(\"Car\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465fa081",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selectionner deux colonnes\n",
        "df.select(\"Car\", \"Cylinders\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c015523",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Créer une nouvelle colonne ayant la veleur 1\n",
        "from pyspark.sql.functions import lit\n",
        "df = df.withColumn('first_column',lit(1)) \n",
        "df.show(5,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "369c3fc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Créer une nouvelle colonne ayant la valeur 2\n",
        "df = df.withColumn('second_column', lit(2))\n",
        "df.show(5,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e254df57",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatener deux colonnes pour en créer une seule\n",
        "from pyspark.sql.functions import concat, col\n",
        "df = df.withColumn('car_model', concat(col(\"Car\"), lit(\" \"), col(\"model\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee39891",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Renommer des colonnes\n",
        "df = df.withColumnRenamed('first_column', 'new_column_one') \\\n",
        "       .withColumnRenamed('second_column', 'new_column_two')\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001779da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compter le nombre de voiture suivant leur origne\n",
        "df.groupBy('Origin').count().show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d96da4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compter le nombre de voitures suivant leur orignes et model\n",
        "df.groupBy('Origin', 'Model').count().show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e5830ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Supprimer une colonne\n",
        "df = df.drop('new_column_one')\n",
        "df.show(5,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bcb546b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selectionner uniquement les voitures européennes\n",
        "europe_filtered= df.filter(col('Origin')=='Europe')\n",
        "europe_filtered.show(5,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc745bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trier les données\n",
        "df.orderBy('Cylinders').show(truncate=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6bdb514",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Créons deux données fictives\n",
        "cars_df = spark.createDataFrame([[1, 'Car A'],[2, 'Car B'],[3, 'Car C']], [\"id\", \"car_name\"])\n",
        "car_price_df = spark.createDataFrame([[1, 1000],[2, 2000],[3, 3000]], [\"id\", \"car_price\"])\n",
        "cars_df.show()\n",
        "car_price_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b380323",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Faisons la jointure entre ces deux données\n",
        "cars_df.join(car_price_df, on=\"id\", how='inner').show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
